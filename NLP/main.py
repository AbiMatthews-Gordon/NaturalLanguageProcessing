from models.tokenizer import Tokenizer
from models.stemmatizer import  Stemmatizer
from models.pos_tagger import PosTagger
from models.lemmatizer import Lemmatizer
from models.lexical_analyzer import LexicalAnalyser


def main():

    # Tokenizer.sentence_tokenizer("test")


main()
